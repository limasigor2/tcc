{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import urllib\n",
    "from os.path import join\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "model_path = path + 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "target_size = (224,224)\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 10\n",
    "SEED = 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=(np.float32))\n",
    "    img = (img - vgg_mean)\n",
    "    return img[:, ::-1] # BGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16(x=None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # layer to preprocess images\n",
    "    model.add(Lambda(preprocess_img, input_shape=(224,224,3), output_shape=(224,224,3)))\n",
    "    #Conv2D(64, kernel_size=(3,3), input_shape=(224,224,3), activation='relu', padding='same')\n",
    "    # conv block 1\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    # conv block 2\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # conv block 3\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    # Fully Connected\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        train_or_test: string 'train' or 'test'.\n",
    "        size: resize the original image.\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(join(path, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../input/labels.csv')\n",
    "submissao = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222\n",
      "10357\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape[0])\n",
    "print(submissao.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_breeds = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[labels['breed'].isin(selected_breeds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['value'] = 0\n",
    "#labels['rank'] = labels.groupby('breed').rank()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_pivot = labels.pivot(index='id', columns='breed', values='value').reset_index().fillna(0)\n",
    "labels_pivot = labels_pivot.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "target = pd.DataFrame(columns=selected_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [0 for x in range(labels_pivot.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in labels.values:\n",
    "    train_data.append(read_img(x[0], 'train', (150,150)))\n",
    "    target.loc[target.shape[0]] = array  \n",
    "    target.loc[target.shape[0]-1][str(x[1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = create_vgg16()\n",
    "#initial_model.load_weights('/home/igor/projetos/tcc/input/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "# Truncate and replace softmax layer for transfer learning\n",
    "x = Dense(120, activation='softmax')(initial_model.layers[-2].output)\n",
    "model = Model(initial_model.input, x)\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "opt = SGD(lr=10e-5)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10222/10222 [==============================] - 2750s 269ms/step - loss: 16.0051 - acc: 0.0069\n",
      "Epoch 2/10\n",
      " 7592/10222 [=====================>........] - ETA: 11:06 - loss: 15.9759 - acc: 0.0088"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(train_data), np.array(target),batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
